{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "#كيفية الوصول إلى أنشطة الكتاب والبيانات"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مرحبا بكم في النشاط الأول من الكتاب.\n",
    "\n",
    "    \n",
    "ستوضح لك تلك الأنشطة كيفية الإفادة من مجال معالجة اللغات الطبيعية في إجراء أنواع متعددة من التحليل المدوني التي نتحدث عنها في كتاب *معالجة اللغات الطبيعية في لسانيات المدونات*. بل وسيتمكن المبتدؤون من خلال هذه الأنشطة من التعرف على هذا المجال عمليا. وإذا ما أردت تفصيلا أكثر، فيمكن الاستزادة من حزمة *text_analytics* التي نستعملها:\n",
    "[https://github.com/jonathandunn/text_analytics](https://github.com/jonathandunn/text_analytics).\n",
    "إذ قد تُستعمل الحزمة للحصول على أمثلة الأكواد البرمجية، والاطلاع على أفضل الممارسات في ذلك. وقد تحملها وتثبتها أيضا على جهازك من خلال نظام إدارة الحزم pip؛ لاستعمالها مباشرة:\n",
    "\n",
    "\n",
    "        pip install textanalytics  #الإصدار الأخير\n",
    "        pip install git+https://github.com/jonathandunn/text_analytics.git  #الإصدار الأحدث\n",
    "\n",
    "سنبدأ بتحميل متطلبات العمل. وهذا يعني فقط أننا سنشغل كل الحزم التي سنحتاجها لإنجاز هذا النشاط. وتلك ستكون منهجيتنا في كل مرة نبدأ فيها العمل في كل نشاط.\n",
    "\n",
    "\n",
    "إذن ابدأ **بتشغيل** السطر الآتي بالنقر على الصندوق، ثم الضغط على زر \"Run\". (ستكون أيقونتك المعتادة لتشغيل الكود). وستلاحظ أنه يوجد في الزاوية العلوية اليسرى من الشاشة دائرة فارغة بجانب \"Python 3\"، ستتلون خلال تشغيل الكود. ولذلك عليك أن تنتظر دائما حتى ينتهي الكود من العمل. وسنزود الكود أيضا بأمر طباعة كلمة  \"DONE! \"في كل مرة ينتهي فيها من العمل.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from text_analytics import TextAnalytics\n",
    "import os\n",
    "import pandas as pd\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "رائع! الآن وقد أعددنا البيئة المناسبة، لنحمّل حزمتنا التي أشرنا إليها. وهنا نُعرِّف البايثون بأن *ai* تشير إلى حزمة *text_analytics*. إذ يمكن أن تسميها بما شئت من المسميات، ولكن هذا المسمى الذي سنعتمده من الآن. وبعد ذلك سيكون أي استعمال بهذه الصيغة **... .ai** إشارة إلى محتويات الحزمة."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ai = TextAnalytics()\n",
    "ai.data_dir = os.path.join(\"..\", \"data\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "سنستعمل في هذه الأنشطة حزمة *text_analytics* لإجراء تحليلاتنا. وذلك سيسهل العمل على من ليس لديه معرفة بلغة البايثون. ولكن إن كانت لديك الخبرة الكافية بالبايثون، فإن حزمة *text_analytics* تتيح بعض الأمثلة التي توضح كل ما تضمنه هذا الكتاب بمزيد من التفصيل."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "والآن بعد أن حملنا كل ما نحتاجه، نبدأ في عرض البيانات. شغل السطر الآتي لتحديد موضع بياناتنا. اسم الملف هو \"economic.congress.1931-2016.gz\"، وفي هذا السطر مسار تخزين البيانات. والمسار لا يعني سوى تحديد المكان الذي يبحث فيه الكود. ثم بعد ذلك نسنعمل حزمة *pandas* لعرض البيانات. وهي مدونة ضخمة أخذنا منها السطور الألف الأولى."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Month Chamber Party  \\\n",
      "0    1931      1       S     R   \n",
      "1    1931      1       S     R   \n",
      "2    1931      1       S     D   \n",
      "3    1931      1       S     R   \n",
      "4    1931      1       S     D   \n",
      "..    ...    ...     ...   ...   \n",
      "995  1931      1       S     D   \n",
      "996  1931      1       S     D   \n",
      "997  1931      1       S     D   \n",
      "998  1931      1       S     D   \n",
      "999  1931      1       S     D   \n",
      "\n",
      "                                                  Text  \n",
      "0    Mr. President. I desire to move at this time. ...  \n",
      "1    Mr. President. in the nature of a memorial. I ...  \n",
      "2    Mr. President. I introduced and had referred t...  \n",
      "3    I ask unanimous consent to have printed in the...  \n",
      "4    Mr. President. during the consideration of the...  \n",
      "..                                                 ...  \n",
      "995  From the Pawnee Agency. at Pawnee. Okla.. I re...  \n",
      "996  I have a telegram from the Muskogee Agency. th...  \n",
      "997  I call attention to a report submitted by the ...  \n",
      "998  It has been in past years. In appropriating mo...  \n",
      "999  The decision makes no distinction between rest...  \n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file = os.path.join(ai.data_dir, \"economic.congress.1931-2016.gz\")\n",
    "df = pd.read_csv(file, nrows = 1000)\n",
    "print(df)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "أمامنا الآن خطابات الكونقرس الأمريكية. وتُظهِر الأعمدة المتعددة المعلومات المتعلقة بكل خطاب، كالسنة التي ألقي فيها الخطاب. وفي عمود النص \"Text\" البيانات الفعلية من كل عينة. ولنلق نظرة الآن على اختيارات عشوائية من العينة. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ai.print_sample(df)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "قد تلاحظ فوضوية البيانات، غير أن ذلك بسبب عدم إجراء أي تهيئة أو معالجة قبلية تجوّد للبيانات."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "هذا كل شيء في نشاطنا الأول! لقد حملنا اليوم متعلقات بيئة العمل، وأنشأنا نسخة من حزمة *text_analytics*، واستعرضنا إحدى المدونات. وهكذا ستكون أنشطتنا في هذه الكتاب قصيرة وبسيطة. ويمكنك دائما أن تبدل وتغير في البيانات من خلال الكود المكتوب في الخلية. والحقيقة أنها طريقة رائعة لتعلم كيفية عمل الأشياء هنا. وتذكر أن بإمكانك دائما الاطلاع على مزيد من التفاصيل من خلال النظر مباشرة في حزمة *text_analytics*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "وفي هذا الكتاب سنعمل على عدد من المدونات المختلفة. يتضمن النوع الأول من المدونات خطابات الكونقرس الرسمية والمقالات الافتتاحية *لصحيفة نيويورك تايمز* بوصف ذلك جزءا من دراسة حالة متعلقة *بالمؤشرات الاجتماعية – الاقتصادية*. وتمتد كلتا المدونتين بين عامي 1931- 2016. وقد تضمن مدونة خطابات الكونقرس حوالي 841 مليون كلمة، فيما تضمنت المدونة الصحفية 341 مليون كلمة (\"economic.nyt.1931-2016.gz\").\n",
    "أما النوع الثاني من المدونات التي سنستعملها فهو الكتب المنشورة من القرن التاسع عشر وبدايات القرن العشرين. وقد قسمنا هذه المدونة الأضخم إلى منشورات لمؤلفين ولدوا بين عامي 1800- 1850، ومؤلفين ولدوا بين عامي 1851-1900. وتضم هذه المدونة إجمالا 1042 مليون كلمة تقريبا. وهنا جزء منها: \"stylistics.authorship_1850.gz\".\n",
    "ويكمل هذه المجموعة من المدونات التي سنعمل عليها النوع الثالث من المدونات ذات المصدر الرقمي: مواقع الإنترنت وتويتر. وتلك البيانات ذات مرجعية جغرافية إذ تعرف كل عينة فيها بالبلد الذي تنتمي إليه. وتتضمن في مجموعها 842 مليون كلمة تقريبا: \"sociolinguistics.english_cities.gz\"، و\"sociolinguistics.english_dialects.gz\".\n",
    "لقد مثلت المدونات السابقة عددا من السجلات اللغوية المختلفة، ولكن جميعها باللغة الإنجليزية. وسنخوض غمار البيانات المتعددة اللغات بمجموعة بيانات تضم 39 لغة من ثلاثة مصادر: ويكيبيديا وتويتر ومواقع الإنترنت. ولكل لغة من هذه اللغات حجم بيانات متساو من المصادر الثلاثة. وتوجد مجموعة المدونات تلك في مجلد مستقل على: \"\\register\\Register.ara.gz\". ولا حظ أن رمز كل لغة يختلف عن الآخر، وفيما عدا ذلك تجد التسميات متسقة.\n",
    "والآن حان دورك! استعمل الصندوق المخصص للكود البرمجي أدنا لتحميل بيانات مختلفة، وطباعة بعض العينات منها.\n"
   ]
  }
 ],
 "metadata": {
  "direction": "rtl",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
